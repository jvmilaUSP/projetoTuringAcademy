{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "df = pd.read_csv(\"bank_train.csv\")\n",
    "df_clean = df.copy()\n",
    "df_test = pd.read_csv(\"bank_test.csv\")\n",
    "df_test_clean = df_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapeamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jvmil\\AppData\\Local\\Temp\\ipykernel_28372\\1280514580.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_clean['y'] = df_clean['y'].replace({\"yes\": 1, \"no\": 0})\n",
      "C:\\Users\\jvmil\\AppData\\Local\\Temp\\ipykernel_28372\\1280514580.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_clean['loan'] = df_clean['loan'].replace({'no': 0, 'n': 0, 'y':1, 'yes':1})\n",
      "C:\\Users\\jvmil\\AppData\\Local\\Temp\\ipykernel_28372\\1280514580.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_clean['default'] = df_clean['default'].replace({'no': 0, 'yes':1})\n",
      "C:\\Users\\jvmil\\AppData\\Local\\Temp\\ipykernel_28372\\1280514580.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_clean['housing'] = df_clean['housing'].replace({'no': 0, 'yes':1})\n",
      "C:\\Users\\jvmil\\AppData\\Local\\Temp\\ipykernel_28372\\1280514580.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_test_clean['loan'] = df_test_clean['loan'].replace({'no': 0, 'n': 0, 'y':1, 'yes':1})\n",
      "C:\\Users\\jvmil\\AppData\\Local\\Temp\\ipykernel_28372\\1280514580.py:8: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_test_clean['default'] = df_test_clean['default'].replace({'no': 0, 'yes':1})\n",
      "C:\\Users\\jvmil\\AppData\\Local\\Temp\\ipykernel_28372\\1280514580.py:9: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_test_clean['housing'] = df_test_clean['housing'].replace({'no': 0, 'yes':1})\n"
     ]
    }
   ],
   "source": [
    "#Treino\n",
    "df_clean['y'] = df_clean['y'].replace({\"yes\": 1, \"no\": 0})\n",
    "df_clean['loan'] = df_clean['loan'].replace({'no': 0, 'n': 0, 'y':1, 'yes':1})\n",
    "df_clean['default'] = df_clean['default'].replace({'no': 0, 'yes':1})\n",
    "df_clean['housing'] = df_clean['housing'].replace({'no': 0, 'yes':1})\n",
    "#Teste\n",
    "df_test_clean['loan'] = df_test_clean['loan'].replace({'no': 0, 'n': 0, 'y':1, 'yes':1})\n",
    "df_test_clean['default'] = df_test_clean['default'].replace({'no': 0, 'yes':1})\n",
    "df_test_clean['housing'] = df_test_clean['housing'].replace({'no': 0, 'yes':1})\n",
    "\n",
    "#MAPEAMENTOS\n",
    "#Treino\n",
    "month_mapping = {\n",
    "    'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6,\n",
    "    'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12\n",
    "}\n",
    "\n",
    "# Aplicar o mapeamento à coluna 'month'\n",
    "df_clean['month'] = df_clean['month'].map(month_mapping)\n",
    "\n",
    "#Teste\n",
    "\n",
    "month_mapping = {\n",
    "    'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6,\n",
    "    'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12\n",
    "}\n",
    "\n",
    "# Aplicar o mapeamento à coluna 'month'\n",
    "df_test_clean['month'] = df_test_clean['month'].map(month_mapping)\n",
    "\n",
    "education_mapping = {\n",
    "    'primary': 1, 'secondary': 2, 'tertiary': 3\n",
    "}\n",
    "\n",
    "# Aplicar o mapeamento à coluna 'month'\n",
    "df_clean['education'] = df_clean['education'].map(education_mapping)\n",
    "#Teste\n",
    "df_test_clean['education'] = df_test_clean['education'].map(education_mapping)\n",
    "\n",
    "marital_mapping = {\n",
    "    'single': 1, 'married': 2, 'divorced': 3\n",
    "}\n",
    "\n",
    "df_clean['marital'] = df_clean['marital'].map(marital_mapping)\n",
    "#Teste\n",
    "df_test_clean['marital'] = df_test_clean['marital'].map(marital_mapping)\n",
    "\n",
    "contact_mapping = {\n",
    "    'cellular': 1, 'unknown': 0, 'telephone': 2\n",
    "}\n",
    "\n",
    "df_clean['contact'] = df_clean['contact'].map(contact_mapping)\n",
    "#Teste\n",
    "df_test_clean['contact'] = df_test_clean['contact'].map(contact_mapping)\n",
    "\n",
    "job_mapping = {\n",
    "    'management':1, 'blue-collar':2, 'student':3, 'self-employed':4, 'technician':5,\n",
    " 'administrator':6, 'retired':7, 'housemaid':8, 'services':9, 'unemployed':10,\n",
    " 'admin.':6, 'unknown':0, 'entrepreneur':11 \n",
    "}\n",
    "\n",
    "df_clean['job'] = df_clean['job'].map(job_mapping)\n",
    "#Teste\n",
    "df_test_clean['job'] = df_test_clean['job'].map(job_mapping)\n",
    "#aa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpeza de colunas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treino\n",
    "df_clean = df_clean.drop(columns=['location'])\n",
    "df_clean = df_clean.drop(columns=['poutcome'])\n",
    "df_clean = df_clean.drop(columns=['id'])\n",
    "#Teste\n",
    "df_test_clean = df_test_clean.drop(columns=['location'])\n",
    "df_test_clean = df_test_clean.drop(columns=['poutcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean[df_clean['job'] != 'unknown']\n",
    "df_clean = df_clean[df_clean['education'] != 'unknown']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remoção de outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean[(df_clean['balance'] < 15000) & (df_clean['balance'] > -5000) ]\n",
    "df_clean = df_clean[(df_clean['age'] <= 80) & (df_clean['age'] > 18)]\n",
    "df_clean = df_clean[(df_clean['previous'] <= 30) ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_clean = df_clean.dropna(subset=['marital'])\n",
    "df_clean = df_clean.dropna(subset=['job'])\n",
    "df_clean = df_clean.dropna(subset=['contact'])\n",
    "df_clean = df_clean.dropna(subset=['education'])\n",
    "df_clean = df_clean.dropna(subset=['previous'])\n",
    "df_clean = df_clean.dropna(subset=['campaign'])\n",
    "df_clean = df_clean.dropna(subset=['campaign'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções auxiliares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(model):\n",
    "    X_test_final = df_test_clean.drop(columns=['id'])\n",
    "    ids = df_test_clean['id']\n",
    "\n",
    "    # Fazer previsões\n",
    "    y_pred_final = model.predict(X_test_final)\n",
    "\n",
    "    # Criar um DataFrame com os resultados\n",
    "    results = pd.DataFrame({\n",
    "        'id': ids,\n",
    "        'y': y_pred_final\n",
    "    })\n",
    "\n",
    "    # Salvar os resultados em um arquivo CSV\n",
    "    results.to_csv('predictions.csv', index=False)\n",
    "    print('Predictions saved to predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de threshhold \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_threshhold(model,valor):\n",
    "    X_test_final = df_test_clean.drop(columns=['id'])\n",
    "    ids = df_test_clean['id']\n",
    "\n",
    "    # Fazer previsões\n",
    "    y_scores = model.predict_proba(X_test_final)[:, 1]\n",
    "    y_pred_adjusted = (y_scores >= valor).astype(int)\n",
    "\n",
    "    # Criar um DataFrame com os resultados\n",
    "    results = pd.DataFrame({\n",
    "        'id': ids,\n",
    "        'y': y_pred_adjusted\n",
    "    })\n",
    "\n",
    "    # Salvar os resultados em um arquivo CSV\n",
    "    results.to_csv('predictions.csv', index=False)\n",
    "    print('Predictions saved to predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_threshhold_alterado_dataSet(model,valor,df_teste):\n",
    "    X_test_final = df_teste.drop(columns=['id'])\n",
    "    ids = df_teste['id']\n",
    "\n",
    "    # Fazer previsões\n",
    "    y_scores = model.predict_proba(X_test_final)[:, 1]\n",
    "    y_pred_adjusted = (y_scores >= valor).astype(int)\n",
    "\n",
    "    # Criar um DataFrame com os resultados\n",
    "    results = pd.DataFrame({\n",
    "        'id': ids,\n",
    "        'y': y_pred_adjusted\n",
    "    })\n",
    "\n",
    "    # Salvar os resultados em um arquivo CSV\n",
    "    results.to_csv('predictions.csv', index=False)\n",
    "    print('Predictions saved to predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def findBestTresh(model, X_test):\n",
    "    y_scores = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    #valores a serem testados\n",
    "    \n",
    "    best_f1 = 0\n",
    "    best_threshold = 0\n",
    "    best_precision = 0\n",
    "    best_recall = 0\n",
    "    \n",
    "    for c in range(20,50):\n",
    "        threshold = c / 100\n",
    "        y_pred_adjusted = (y_scores >= threshold).astype(int)\n",
    "        precision = precision_score(y_test, y_pred_adjusted, pos_label=1)\n",
    "        recall = recall_score(y_test, y_pred_adjusted, pos_label=1)\n",
    "        f1 = f1_score(y_test, y_pred_adjusted, pos_label=1)\n",
    "        \n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "            best_precision = precision\n",
    "            best_recall = recall\n",
    "    \n",
    "    #print(f\"Optimal Threshold: {best_threshold}\")\n",
    "    #print(f\"Best Precision: {best_precision:.2f}\")\n",
    "    #print(f\"Best Recall: {best_recall:.2f}\")\n",
    "    #print(f\"Best F1 Score: {best_f1:.2f}\")\n",
    "    \n",
    "    return best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def findBestTreshByPrecision(model, X_test):\n",
    "    y_scores = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    #valores a serem testados\n",
    "    thresholds = [0.2,0.25,0.27, 0.271, 0.272, 0.273, 0.274, 0.275, 0.276, 0.277, 0.278, 0.279,0.3,0.35,0.4\n",
    "                  ,0.45,0.5]\n",
    "    \n",
    "    best_f1 = 0\n",
    "    best_threshold = 0\n",
    "    best_precision = 0\n",
    "    best_recall = 0\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        y_pred_adjusted = (y_scores >= threshold).astype(int)\n",
    "        precision = precision_score(y_test, y_pred_adjusted, pos_label=1)\n",
    "        recall = recall_score(y_test, y_pred_adjusted, pos_label=1)\n",
    "        f1 = f1_score(y_test, y_pred_adjusted, pos_label=1)\n",
    "        \n",
    "        if precision > best_precision:\n",
    "            best_f1 = f1\n",
    "            best_threshold = threshold\n",
    "            best_precision = precision\n",
    "            best_recall = recall\n",
    "    \n",
    "    print(f\"Optimal Threshold: {best_threshold}\")\n",
    "    print(f\"Best Precision: {best_precision:.2f}\")\n",
    "    print(f\"Best Recall: {best_recall:.2f}\")\n",
    "    print(f\"Best F1 Score: {best_f1:.2f}\")\n",
    "    \n",
    "    return best_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escolha do modelo (lazypredict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
      "Model                                                                           \n",
      "XGBClassifier                      0.90               0.71     0.71      0.89   \n",
      "DecisionTreeClassifier             0.87               0.71     0.71      0.88   \n",
      "LGBMClassifier                     0.90               0.69     0.69      0.89   \n",
      "BaggingClassifier                  0.89               0.67     0.67      0.88   \n",
      "RandomForestClassifier             0.90               0.66     0.66      0.89   \n",
      "PassiveAggressiveClassifier        0.78               0.66     0.66      0.81   \n",
      "AdaBoostClassifier                 0.89               0.65     0.65      0.88   \n",
      "NearestCentroid                    0.66               0.64     0.64      0.72   \n",
      "QuadraticDiscriminantAnalysis      0.79               0.64     0.64      0.81   \n",
      "ExtraTreeClassifier                0.85               0.63     0.63      0.85   \n",
      "GaussianNB                         0.77               0.63     0.63      0.79   \n",
      "BernoulliNB                        0.88               0.61     0.61      0.86   \n",
      "ExtraTreesClassifier               0.89               0.60     0.60      0.87   \n",
      "LabelSpreading                     0.85               0.59     0.59      0.84   \n",
      "LabelPropagation                   0.84               0.59     0.59      0.84   \n",
      "KNeighborsClassifier               0.88               0.56     0.56      0.85   \n",
      "SVC                                0.88               0.52     0.52      0.84   \n",
      "LinearDiscriminantAnalysis         0.88               0.51     0.51      0.83   \n",
      "LogisticRegression                 0.88               0.51     0.51      0.83   \n",
      "CalibratedClassifierCV             0.88               0.50     0.50      0.83   \n",
      "Perceptron                         0.86               0.50     0.50      0.82   \n",
      "LinearSVC                          0.88               0.50     0.50      0.83   \n",
      "RidgeClassifierCV                  0.88               0.50     0.50      0.83   \n",
      "RidgeClassifier                    0.88               0.50     0.50      0.83   \n",
      "SGDClassifier                      0.88               0.50     0.50      0.83   \n",
      "DummyClassifier                    0.88               0.50     0.50      0.83   \n",
      "\n",
      "                               Time Taken  \n",
      "Model                                      \n",
      "XGBClassifier                        1.38  \n",
      "DecisionTreeClassifier               0.20  \n",
      "LGBMClassifier                       0.30  \n",
      "BaggingClassifier                    1.07  \n",
      "RandomForestClassifier               3.20  \n",
      "PassiveAggressiveClassifier          0.14  \n",
      "AdaBoostClassifier                   1.11  \n",
      "NearestCentroid                      0.06  \n",
      "QuadraticDiscriminantAnalysis        0.09  \n",
      "ExtraTreeClassifier                  0.05  \n",
      "GaussianNB                           0.05  \n",
      "BernoulliNB                          0.05  \n",
      "ExtraTreesClassifier                 2.24  \n",
      "LabelSpreading                      67.93  \n",
      "LabelPropagation                    68.94  \n",
      "KNeighborsClassifier                 3.99  \n",
      "SVC                                 19.11  \n",
      "LinearDiscriminantAnalysis           0.19  \n",
      "LogisticRegression                   0.09  \n",
      "CalibratedClassifierCV               0.19  \n",
      "Perceptron                           0.09  \n",
      "LinearSVC                            0.11  \n",
      "RidgeClassifierCV                    0.06  \n",
      "RidgeClassifier                      0.06  \n",
      "SGDClassifier                        0.09  \n",
      "DummyClassifier                      0.04  \n"
     ]
    }
   ],
   "source": [
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testes com o modelo XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_clean.drop(columns=['y'])\n",
    "y = df_clean['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=22)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['day'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[133], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m cols_to_normalize \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalance\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcampaign\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpdays\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprevious\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m----> 6\u001b[0m X_train[cols_to_normalize] \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcols_to_normalize\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      7\u001b[0m X_test[cols_to_normalize] \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_test[cols_to_normalize])\n",
      "File \u001b[1;32mc:\\Users\\André DIas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4096\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4095\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4096\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4098\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\André DIas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6199\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6197\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6199\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6201\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6203\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\André DIas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6251\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6250\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6251\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['day'] not in index\""
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "cols_to_normalize = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train[cols_to_normalize] = scaler.fit_transform(X_train[cols_to_normalize])\n",
    "X_test[cols_to_normalize] = scaler.transform(X_test[cols_to_normalize])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinando modelo e testando acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.90\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      5660\n",
      "           1       0.58      0.48      0.52       711\n",
      "\n",
      "    accuracy                           0.90      6371\n",
      "   macro avg       0.76      0.72      0.73      6371\n",
      "weighted avg       0.90      0.90      0.90      6371\n",
      "\n",
      "Predictions saved to predictions.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "## TREINO DE MODELO\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "modelXGBC = XGBClassifier()\n",
    "modelXGBC.fit(X_train, y_train)\n",
    "\n",
    "#TESTANDO ACURACIA\n",
    "\n",
    "y_pred = modelXGBC.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print('Classification Report:\\n', report)\n",
    "predictions(modelXGBC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alterando hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "xgb = XGBClassifier(objective = 'binary:logistic', use_label_encoder = False, eval_metric = 'logloss')\n",
    "\n",
    "param_grid = {\n",
    "   'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'learning_rate': [0.01, 0.02, 0.05, 0.1],\n",
    "    'reg_alpha': [0.0, 0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "# Usar GridSearchCV para encontrar os melhores hiperparâmetros\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=5, scoring='f1', verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Melhor combinação de hiperparâmetros\n",
    "print(\"Melhores hiperparâmetros:\", grid_search.best_params_)\n",
    "\n",
    "# Treinar o modelo com os melhores hiperparâmetros\n",
    "best_params = grid_search.best_params_\n",
    "best_model = XGBClassifier(**best_params)\n",
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.90\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95      5635\n",
      "           1       0.61      0.46      0.53       737\n",
      "\n",
      "    accuracy                           0.90      6372\n",
      "   macro avg       0.77      0.71      0.74      6372\n",
      "weighted avg       0.89      0.90      0.90      6372\n",
      "\n",
      "Predictions saved to predictions.csv\n"
     ]
    }
   ],
   "source": [
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_best)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "report = classification_report(y_test, y_pred_best)\n",
    "print('Classification Report:\\n', report)\n",
    "\n",
    "predictions(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste com oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train = df_clean.drop(columns=['y'])\n",
    "y_train = df_clean['y']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearch para hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "xgb = XGBClassifier(objective = 'binary:logistic', use_label_encoder = False, eval_metric = 'logloss')\n",
    "\n",
    "grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'learning_rate': [0.01, 0.02, 0.05, 0.1],\n",
    "    'reg_alpha': [0.0, 0.1, 0.5, 1.0]}\n",
    "\n",
    "grid_search = GridSearchCV(estimator = xgb, param_grid = grid, cv = 5, scoring = 'f1', verbose = 3, n_jobs = -1)\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "print(\"Melhores hiperparâmetros:\", grid_search.best_params_)\n",
    "\n",
    "# Melhor modelo\n",
    "best_params = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = XGBClassifier(objective = 'binary:logistic', use_label_encoder = False, eval_metric = 'logloss', **best_params)\n",
    "best_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Prever no conjunto de teste\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Acurácia: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "# Relatório de classificação\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "predictions(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste deletando a coluna de dias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_sem_dias = df_clean.copy()\n",
    "df_clean_sem_dias = df_clean_sem_dias.drop(columns=['day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treino de modelo XGBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_clean_sem_dias.drop(columns=['y'])\n",
    "y = df_clean_sem_dias['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste de previsão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coluna sem dias\n",
      "Accuracy: 0.90\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95      5660\n",
      "           1       0.59      0.45      0.51       711\n",
      "\n",
      "    accuracy                           0.90      6371\n",
      "   macro avg       0.76      0.71      0.73      6371\n",
      "weighted avg       0.89      0.90      0.90      6371\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "## TREINO DE MODELO\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "modelXGBC = XGBClassifier()\n",
    "modelXGBC.fit(X_train, y_train)\n",
    "\n",
    "#TESTANDO ACURACIA\n",
    "\n",
    "y_pred = modelXGBC.predict(X_test)\n",
    "print(\"Coluna sem dias\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print('Classification Report:\\n', report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste separando a idade em faixas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alterando as idades em faixas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 24,30, 59, 100]  # Definindo os limites das faixas\n",
    "labels = [1, 2, 3,4]  # Rótulos para cada faixa\n",
    "\n",
    "# Função para mapear as idades ignorando NaNs\n",
    "def map_age(age):\n",
    "    if pd.isna(age):\n",
    "        return age\n",
    "    else:\n",
    "        return pd.cut([age], bins=bins, labels=labels, right=True)[0]\n",
    "    \n",
    "df_clean_faixa_idade = df_clean.copy()\n",
    "df_clean_faixa_idade['age'] = df_clean_faixa_idade['age'].apply(map_age)\n",
    "df_test_clean_faixa_idade = df_test_clean.copy()\n",
    "\n",
    "\n",
    "\n",
    "# Aplicar a função de mapeamento\n",
    "df_test_clean_faixa_idade['age'] = df_test_clean_faixa_idade['age'].apply(map_age)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_clean_faixa_idade' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, classification_report\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> 5\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf_clean_faixa_idade\u001b[49m\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m y \u001b[38;5;241m=\u001b[39m df_clean_faixa_idade[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      8\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m22\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_clean_faixa_idade' is not defined"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_clean_faixa_idade.drop(columns=['y'])\n",
    "y = df_clean_faixa_idade['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalização\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_faixa_idade['balance'] = np.sign(df_clean_faixa_idade['balance']) * np.log1p(np.abs(df_clean_faixa_idade['balance']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train = df_clean_faixa_idade.drop(columns=['y'])\n",
    "y_train = df_clean_faixa_idade['y']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=22)\n",
    "\n",
    "\n",
    "smote = SMOTE(sampling_strategy=0.55, k_neighbors=3, random_state=22)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coluna faixa idade\n",
      "Accuracy: 0.90\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94      5588\n",
      "           1       0.62      0.49      0.55       782\n",
      "\n",
      "    accuracy                           0.90      6370\n",
      "   macro avg       0.77      0.73      0.75      6370\n",
      "weighted avg       0.89      0.90      0.90      6370\n",
      "\n",
      "Predictions saved to predictions.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "## TREINO DE MODELO\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "modelXGBC = XGBClassifier()\n",
    "modelXGBC.fit(X_train_res, y_train_res)\n",
    "\n",
    "#TESTANDO ACURACIA\n",
    "\n",
    "y_pred = modelXGBC.predict(X_test)\n",
    "print(\"Coluna faixa idade\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "print('Classification Report:\\n', report)\n",
    "predictions(modelXGBC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste com probabilidade alterada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold: 0.21\n",
      "Best Precision: 0.51\n",
      "Best Recall: 0.77\n",
      "Best F1 Score: 0.61\n",
      "Coluna faixa idade\n",
      "Accuracy: 0.90\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94      5588\n",
      "           1       0.62      0.49      0.55       782\n",
      "\n",
      "    accuracy                           0.90      6370\n",
      "   macro avg       0.77      0.73      0.75      6370\n",
      "weighted avg       0.89      0.90      0.90      6370\n",
      "\n",
      "Predictions saved to predictions.csv\n",
      "teste\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93      5588\n",
      "           1       0.51      0.77      0.61       782\n",
      "\n",
      "    accuracy                           0.88      6370\n",
      "   macro avg       0.74      0.83      0.77      6370\n",
      "weighted avg       0.91      0.88      0.89      6370\n",
      "\n",
      "Predictions saved to predictions.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#treinar modelo\n",
    "modelXGBC = XGBClassifier()\n",
    "modelXGBC.fit(X_train_res, y_train_res)\n",
    "#threshhold\n",
    "m = findBestTresh(modelXGBC,X_test)\n",
    "y_scores = modelXGBC.predict_proba(X_test)[:, 1]\n",
    "y_pred_adjusted = (y_scores >= m).astype(int)\n",
    "y_pred = modelXGBC.predict(X_test)\n",
    "#prints\n",
    "print(\"Coluna faixa idade\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "report = classification_report(y_test, y_pred)\n",
    "print('Classification Report:\\n', report)\n",
    "predictions(modelXGBC)\n",
    "print(\"teste\")\n",
    "print(classification_report(y_test, y_pred_adjusted))\n",
    "predictions_threshhold(modelXGBC,m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otimização com hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Usar GridSearchCV para encontrar os melhores hiperparâmetros\u001b[39;00m\n\u001b[0;32m     34\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mxgb, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train_res\u001b[49m, y_train_res)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Melhor combinação de hiperparâmetros\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMelhores hiperparâmetros:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_res' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Supondo que X_train_res e y_train_res já estejam definidos\n",
    "\n",
    "# Definir o classificador e o grid de parâmetros\n",
    "xgb = XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'max_depth': [3, 5, 7, 10],\n",
    "#     'learning_rate': [0.01, 0.02, 0.05, 0.1],\n",
    "#     'reg_alpha': [0.0, 0.1, 0.5, 1.0],\n",
    "#     'subsample': [0.6, 0.8, 1.0],\n",
    "#     'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "#     'min_child_weight': [1, 3, 5],\n",
    "#     'gamma': [0, 0.1, 0.3, 0.5]\n",
    "# }\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [10],\n",
    "    'learning_rate': [0.02],\n",
    "    'reg_alpha': [0.0],\n",
    "    'subsample': [1.0],\n",
    "    'colsample_bytree': [1.0],\n",
    "    'min_child_weight': [1],\n",
    "    'gamma': [0]\n",
    "}\n",
    "\n",
    "# Usar GridSearchCV para encontrar os melhores hiperparâmetros\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=5, scoring='f1', verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Melhor combinação de hiperparâmetros\n",
    "print(\"Melhores hiperparâmetros:\", grid_search.best_params_)\n",
    "\n",
    "# Treinar o modelo com os melhores hiperparâmetros\n",
    "best_params = grid_search.best_params_\n",
    "best_model = XGBClassifier(**best_params, use_label_encoder=False, eval_metric='logloss')\n",
    "best_model.fit(X_train_res, y_train_res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperparametros rodando "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jvmil\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:158: UserWarning: [12:47:09] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coluna faixa idade\n",
      "Accuracy: 0.90\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      5630\n",
      "           1       0.65      0.34      0.45       739\n",
      "\n",
      "    accuracy                           0.90      6369\n",
      "   macro avg       0.79      0.66      0.70      6369\n",
      "weighted avg       0.89      0.90      0.89      6369\n",
      "\n",
      "teste\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94      5630\n",
      "           1       0.53      0.76      0.63       739\n",
      "\n",
      "    accuracy                           0.90      6369\n",
      "   macro avg       0.75      0.83      0.78      6369\n",
      "weighted avg       0.92      0.90      0.90      6369\n",
      "\n",
      "Predictions saved to predictions.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#treinar modelo\n",
    "best_model.fit(X_train, y_train)\n",
    "#threshhold\n",
    "m = findBestTresh(best_model,X_test)\n",
    "y_scores = best_model.predict_proba(X_test)[:, 1]\n",
    "y_pred_adjusted = (y_scores >= m).astype(int)\n",
    "y_pred = best_model.predict(X_test)\n",
    "#prints\n",
    "print(\"Coluna faixa idade\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "report = classification_report(y_test, y_pred)\n",
    "print('Classification Report:\\n', report)\n",
    "print(\"teste\")\n",
    "print(classification_report(y_test, y_pred_adjusted))\n",
    "\n",
    "predictions_threshhold_alterado_dataSet(best_model,m,df_test_clean_faixa_idade)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alterando loan e housing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clonagem de datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_loan_housing = df_clean.copy()\n",
    "df_clean_loan_housing.loc[df_clean_loan_housing['housing'] == 1, 'loan'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_clean_loan_housing.drop(columns=['y'])\n",
    "y = df_clean_loan_housing['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train = df_clean_loan_housing.drop(columns=['y'])\n",
    "y_train = df_clean_loan_housing['y']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=22)\n",
    "\n",
    "\n",
    "smote = SMOTE(sampling_strategy=0.55, k_neighbors=7, random_state=22)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jvmil\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:158: UserWarning: [15:02:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros: {'colsample_bytree': 1.0, 'gamma': 0, 'learning_rate': 0.02, 'max_depth': 10, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'subsample': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.02, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.02, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.02, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "xgb = XGBClassifier(objective = 'binary:logistic', use_label_encoder = False, eval_metric = 'logloss')\n",
    "\n",
    "# param_grid = {\n",
    "#    'n_estimators': [100, 200, 300],\n",
    "#     'max_depth': [3, 5, 7, 10],\n",
    "#     'learning_rate': [0.01, 0.02, 0.05, 0.1],\n",
    "#     'reg_alpha': [0.0, 0.1, 0.5, 1.0]\n",
    "# }\n",
    "param_grid = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [10],\n",
    "    'learning_rate': [0.02],\n",
    "    'reg_alpha': [0.0],\n",
    "    'subsample': [1.0],\n",
    "    'colsample_bytree': [1.0],\n",
    "    'min_child_weight': [1],\n",
    "    'gamma': [0]\n",
    "}\n",
    "# Usar GridSearchCV para encontrar os melhores hiperparâmetros\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=5, scoring='f1', verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Melhor combinação de hiperparâmetros\n",
    "print(\"Melhores hiperparâmetros:\", grid_search.best_params_)\n",
    "\n",
    "# Treinar o modelo com os melhores hiperparâmetros\n",
    "best_params = grid_search.best_params_\n",
    "best_model = XGBClassifier(**best_params)\n",
    "best_model.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold: 0.29\n",
      "Best Precision: 0.50\n",
      "Best Recall: 0.72\n",
      "Best F1 Score: 0.59\n",
      "Coluna faixa idade\n",
      "Accuracy: 0.89\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94      5588\n",
      "           1       0.62      0.37      0.46       782\n",
      "\n",
      "    accuracy                           0.89      6370\n",
      "   macro avg       0.77      0.67      0.70      6370\n",
      "weighted avg       0.88      0.89      0.88      6370\n",
      "\n",
      "teste\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93      5588\n",
      "           1       0.50      0.72      0.59       782\n",
      "\n",
      "    accuracy                           0.88      6370\n",
      "   macro avg       0.73      0.81      0.76      6370\n",
      "weighted avg       0.90      0.88      0.89      6370\n",
      "\n",
      "Predictions saved to predictions.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "#threshhold\n",
    "m = findBestTresh(best_model,X_test)\n",
    "y_scores = best_model.predict_proba(X_test)[:, 1]\n",
    "y_pred_adjusted = (y_scores >= m).astype(int)\n",
    "y_pred = best_model.predict(X_test)\n",
    "#prints\n",
    "print(\"Coluna faixa idade\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "report = classification_report(y_test, y_pred)\n",
    "print('Classification Report:\\n', report)\n",
    "print(\"teste\")\n",
    "print(classification_report(y_test, y_pred_adjusted))\n",
    "\n",
    "predictions_threshhold(best_model,m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validação Cruzada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93     28152\n",
      "           1       0.50      0.76      0.61      3694\n",
      "\n",
      "    accuracy                           0.89     31846\n",
      "   macro avg       0.74      0.83      0.77     31846\n",
      "weighted avg       0.91      0.89      0.89     31846\n",
      "\n",
      "Predictions saved to predictions.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "data, target = df_clean_faixa_idade.drop(columns = ['y']), df_clean_faixa_idade['y']\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "final_predictions = []\n",
    "final_targets = []\n",
    "best_thresholds = []\n",
    "\n",
    "for train_index, test_index in kf.split(data, target):\n",
    "    \n",
    "    # Dividir os dados em conjuntos de treino e teste\n",
    "    X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Aplicação do oversampling no conjunto de treino\n",
    "    smote = SMOTE(sampling_strategy=0.55, k_neighbors=7, random_state=22)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Treinamento do modelo\n",
    "    model = XGBClassifier()\n",
    "    model.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    m = findBestTresh(model,X_test)\n",
    "    best_thresholds.append(m)\n",
    "\n",
    "    y_scores = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred_adjusted = (y_scores >= m).astype(int)\n",
    "    \n",
    "    final_predictions.extend(y_pred_adjusted)\n",
    "    final_targets.extend(y_test)\n",
    "    print()\n",
    "\n",
    "average_threshold = np.mean(best_thresholds)\n",
    "print(classification_report(final_targets, final_predictions))\n",
    "predictions_threshhold_alterado_dataSet(model, average_threshold,df_test_clean_faixa_idade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X = df_clean_faixa_idade.drop(columns=['y'])\n",
    "y = df_clean_faixa_idade['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=22)\n",
    "\n",
    "smote = SMOTE(sampling_strategy=0.55, k_neighbors=7, random_state=22)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teste\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93      5588\n",
      "           1       0.52      0.74      0.61       782\n",
      "\n",
      "    accuracy                           0.88      6370\n",
      "   macro avg       0.74      0.82      0.77      6370\n",
      "weighted avg       0.91      0.88      0.89      6370\n",
      "\n",
      "Predictions saved to predictions.csv\n"
     ]
    }
   ],
   "source": [
    "#treinar modelo\n",
    "model.fit(X_train_res, y_train_res)\n",
    "#threshhold\n",
    "\n",
    "y_scores = model.predict_proba(X_test)[:, 1]\n",
    "y_pred_adjusted = (y_scores >= average_threshold).astype(int)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"teste\")\n",
    "print(classification_report(y_test, y_pred_adjusted))\n",
    "predictions_threshhold(model,average_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[142], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m params \u001b[38;5;129;01min\u001b[39;00m ParameterGrid(param_grid):\n\u001b[0;32m     23\u001b[0m     model \u001b[38;5;241m=\u001b[39m XGBClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m---> 24\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_res\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_res\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     m \u001b[38;5;241m=\u001b[39m findBestTresh(model,X_test)\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# Obter as probabilidades previstas para a classe positiva\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\André DIas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\André DIas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py:1531\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1511\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[0;32m   1512\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1513\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1514\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1528\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[0;32m   1529\u001b[0m )\n\u001b[1;32m-> 1531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1546\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\André DIas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\André DIas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\André DIas\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2100\u001b[0m     _check_call(\n\u001b[1;32m-> 2101\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[0;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2104\u001b[0m     )\n\u001b[0;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Definindo o espaço de hiperparâmetros\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],           # Menos opções para número de árvores\n",
    "    'learning_rate': [0.01, 0.05, 0.1],       # Três níveis de taxa de aprendizado\n",
    "    'max_depth': [3, 5],                      # Dois níveis de profundidade máxima das árvores\n",
    "    'subsample': [0.8, 1.0],                  # Dois tamanhos de amostra\n",
    "    'colsample_bytree': [0.8, 1.0],           # Dois níveis de features usadas para cada árvore\n",
    "    'gamma': [0, 0.1],                        # Dois valores para a regularização gamma\n",
    "    'min_child_weight': [1, 3]                # Dois níveis de peso mínimo da folha\n",
    "}\n",
    "\n",
    "best_f1 = 0\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "# Loop sobre todas as combinações de hiperparâmetros\n",
    "for params in ParameterGrid(param_grid):\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "    \n",
    "    m = findBestTresh(model,X_test)\n",
    "    # Obter as probabilidades previstas para a classe positiva\n",
    "    y_scores = model.predict_proba(X_test)[:, 1]\n",
    "    # Aplicar o threshold fixo\n",
    "    y_pred_adjusted = (y_scores >= average_threshold).astype(int)\n",
    "    \n",
    "    # Calcular o F1 Score com o threshold ajustado\n",
    "    f1 = f1_score(y_test, y_pred_adjusted)\n",
    "    \n",
    "    # Armazenar o melhor modelo e hiperparâmetros\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_params = params\n",
    "        best_model = model\n",
    "\n",
    "\n",
    "y_scores = best_model.predict_proba(X_test)[:, 1]\n",
    "y_pred_adjusted = (y_scores >= average_threshold).astype(int)\n",
    "\n",
    "# Resultados finais\n",
    "print(f\"Melhores parâmetros: {best_params}\")\n",
    "print(f\"Melhor F1 Score ajustado: {best_f1}\")\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred_adjusted))\n",
    "\n",
    "predictions_threshhold(best_model,average_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300, 'subsample': 1.0}\n",
      "Melhor F1 Score ajustado: 0.6085918854415274\n",
      "Melhor Threshold: 0.32\n",
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      5638\n",
      "           1       0.54      0.70      0.61       732\n",
      "\n",
      "    accuracy                           0.90      6370\n",
      "   macro avg       0.75      0.81      0.77      6370\n",
      "weighted avg       0.91      0.90      0.90      6370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Definição dos dados e rótulos\n",
    "data, target = df_clean_faixa_idade.drop(columns=['y']), df_clean_faixa_idade['y']\n",
    "\n",
    "# Divisão dos dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Aplicação do oversampling no conjunto de treino\n",
    "smote = SMOTE(sampling_strategy=0.55, k_neighbors=7, random_state=22)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Definição do espaço de hiperparâmetros\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5],\n",
    "    'subsample': [0.8, 1.0],\n",
    "}\n",
    "\n",
    "best_f1 = 0\n",
    "best_params = None\n",
    "best_model = None\n",
    "best_threshold = None\n",
    "\n",
    "# Loop sobre todas as combinações de hiperparâmetros\n",
    "for params in ParameterGrid(param_grid):\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "    \n",
    "    # Encontre o melhor threshold para o conjunto de teste\n",
    "    y_scores = model.predict_proba(X_test)[:, 1]\n",
    "    best_threshold = findBestTresh(model, X_test)\n",
    "    y_pred_adjusted = (y_scores >= best_threshold).astype(int)\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred_adjusted)\n",
    " \n",
    "    # Armazenar o melhor modelo, hiperparâmetros e threshold\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_params = params\n",
    "        best_model = model\n",
    "        best_threshold = best_threshold\n",
    "\n",
    "# Relatório de classificação final com o melhor modelo e threshold\n",
    "y_scores = best_model.predict_proba(X_test)[:, 1]\n",
    "y_pred_adjusted = (y_scores >= best_threshold).astype(int)\n",
    "\n",
    "print(f\"Melhores parâmetros: {best_params}\")\n",
    "print(f\"Melhor F1 Score ajustado: {best_f1}\")\n",
    "print(f\"Melhor Threshold: {best_threshold}\")\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred_adjusted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste maluco\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      5631\n",
      "           1       0.65      0.81      0.72       739\n",
      "\n",
      "    accuracy                           0.93      6370\n",
      "   macro avg       0.81      0.87      0.84      6370\n",
      "weighted avg       0.94      0.93      0.93      6370\n",
      "\n",
      "{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300, 'reg_alpha': 0.01, 'reg_lambda': 1.0, 'subsample': 0.8}\n",
      "0.35\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      5631\n",
      "           1       0.68      0.78      0.72       738\n",
      "\n",
      "    accuracy                           0.93      6369\n",
      "   macro avg       0.82      0.87      0.84      6369\n",
      "weighted avg       0.94      0.93      0.93      6369\n",
      "\n",
      "{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300, 'reg_alpha': 0.01, 'reg_lambda': 1.0, 'subsample': 0.8}\n",
      "0.35\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96      5630\n",
      "           1       0.64      0.78      0.70       739\n",
      "\n",
      "    accuracy                           0.92      6369\n",
      "   macro avg       0.81      0.86      0.83      6369\n",
      "weighted avg       0.93      0.92      0.93      6369\n",
      "\n",
      "{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300, 'reg_alpha': 0.01, 'reg_lambda': 1.0, 'subsample': 0.8}\n",
      "0.35\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      5630\n",
      "           1       0.66      0.76      0.70       739\n",
      "\n",
      "    accuracy                           0.93      6369\n",
      "   macro avg       0.81      0.85      0.83      6369\n",
      "weighted avg       0.93      0.93      0.93      6369\n",
      "\n",
      "{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300, 'reg_alpha': 0.01, 'reg_lambda': 1.0, 'subsample': 0.8}\n",
      "0.35\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96      5630\n",
      "           1       0.68      0.79      0.73       739\n",
      "\n",
      "    accuracy                           0.93      6369\n",
      "   macro avg       0.83      0.87      0.85      6369\n",
      "weighted avg       0.94      0.93      0.93      6369\n",
      "\n",
      "{'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300, 'reg_alpha': 0.01, 'reg_lambda': 1.0, 'subsample': 0.8}\n",
      "0.36\n",
      "\n",
      "Modelo final\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96     28152\n",
      "           1       0.70      0.80      0.75      3694\n",
      "\n",
      "    accuracy                           0.94     31846\n",
      "   macro avg       0.84      0.88      0.86     31846\n",
      "weighted avg       0.94      0.94      0.94     31846\n",
      "\n",
      "Predictions saved to predictions.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "data, target = df_clean_faixa_idade.drop(columns = ['y']), df_clean_faixa_idade['y']\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "final_predictions = []\n",
    "final_targets = []\n",
    "best_thresholds = []\n",
    "parametros = []\n",
    "best_f1 = 0\n",
    "best_params = None\n",
    "best_model = None\n",
    "best_tresh = None\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'reg_alpha': [0.01],       # Regularização L1\n",
    "    'reg_lambda': [1.0]     # Regularização L2\n",
    "}\n",
    "\n",
    "for train_index, test_index in kf.split(data, target):\n",
    "    \n",
    "    # Dividir os dados em conjuntos de treino e teste\n",
    "    X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Aplicação do oversampling no conjunto de treino\n",
    "    smote = SMOTE(sampling_strategy=0.55, k_neighbors=7, random_state=22)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    for params in ParameterGrid(param_grid):\n",
    "        model = XGBClassifier(**params)\n",
    "        model.fit(X_train_res, y_train_res)\n",
    "        m = findBestTresh(model,X_test)\n",
    "    \n",
    "        y_scores = model.predict_proba(X_test)[:, 1]\n",
    "        y_pred_adjusted = (y_scores >= m).astype(int)\n",
    "\n",
    "        f1 = f1_score(y_test, y_pred_adjusted)\n",
    "     \n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_params = params\n",
    "            best_model = model\n",
    "            best_tresh = m\n",
    " \n",
    "    best_thresholds.append(best_tresh)\n",
    "    parametros.append(best_params)\n",
    "\n",
    "    y_scores = best_model.predict_proba(X_test)[:, 1]\n",
    "    y_pred_adjusted = (y_scores >= best_tresh).astype(int)\n",
    "    \n",
    "    final_predictions.extend(y_pred_adjusted)\n",
    "    final_targets.extend(y_test)\n",
    "    print(classification_report(y_test, y_pred_adjusted))\n",
    "    print(best_params)\n",
    "    print(best_tresh)\n",
    "    print()\n",
    "\n",
    "average_threshold = np.mean(best_thresholds)\n",
    "best_model = XGBClassifier(**best_params)\n",
    "best_model.fit(data, target)\n",
    "\n",
    "y_scores = best_model.predict_proba(data)[:, 1]\n",
    "y_pred_final = (y_scores >= average_threshold).astype(int)\n",
    "\n",
    "print(\"Modelo final\")\n",
    "print(classification_report(target, y_pred_final))\n",
    "predictions_threshhold_alterado_dataSet(best_model,average_threshold,df_test_clean_faixa_idade)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X = df_clean_faixa_idade.drop(columns=['y'])\n",
    "y = df_clean_faixa_idade['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=22)\n",
    "\n",
    "smote = SMOTE(sampling_strategy=0.55, k_neighbors=7, random_state=22)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teste\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      5588\n",
      "           1       0.58      0.65      0.61       782\n",
      "\n",
      "    accuracy                           0.90      6370\n",
      "   macro avg       0.77      0.79      0.78      6370\n",
      "weighted avg       0.90      0.90      0.90      6370\n",
      "\n",
      "Predictions saved to predictions.csv\n"
     ]
    }
   ],
   "source": [
    "#treinar modelo\n",
    "best_params_avg = {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 300, 'subsample': 0.8}\n",
    "\n",
    "final_model = XGBClassifier(**best_params_avg)\n",
    "final_model.fit(X_train_res, y_train_res)\n",
    "#threshhold\n",
    "\n",
    "y_scores = final_model.predict_proba(X_test)[:, 1]\n",
    "y_pred_adjusted = (y_scores >= average_threshold).astype(int)\n",
    "\n",
    "print(\"teste\")\n",
    "print(classification_report(y_test, y_pred_adjusted))\n",
    "predictions_threshhold(final_model,average_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validação cruzada com busca de hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold: 0.42\n",
      "Best Precision: 0.48\n",
      "Best Recall: 0.70\n",
      "Best F1 Score: 0.57\n",
      "\n",
      "Optimal Threshold: 0.32\n",
      "Best Precision: 0.43\n",
      "Best Recall: 0.78\n",
      "Best F1 Score: 0.55\n",
      "\n",
      "Optimal Threshold: 0.42\n",
      "Best Precision: 0.47\n",
      "Best Recall: 0.68\n",
      "Best F1 Score: 0.55\n",
      "\n",
      "Optimal Threshold: 0.36\n",
      "Best Precision: 0.45\n",
      "Best Recall: 0.71\n",
      "Best F1 Score: 0.55\n",
      "\n",
      "Optimal Threshold: 0.4\n",
      "Best Precision: 0.48\n",
      "Best Recall: 0.73\n",
      "Best F1 Score: 0.58\n",
      "\n",
      "{'learning_rate': 0.01, 'max_depth': 7.0, 'n_estimators': 200.0, 'reg_alpha': 0.02}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.92     28152\n",
      "           1       0.46      0.72      0.56      3694\n",
      "\n",
      "    accuracy                           0.87     31846\n",
      "   macro avg       0.71      0.80      0.74     31846\n",
      "weighted avg       0.90      0.87      0.88     31846\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "data, target = df_clean_faixa_idade.drop(columns = ['y']), df_clean_faixa_idade['y']\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "final_predictions = []\n",
    "final_targets = []\n",
    "best_thresholds = []\n",
    "best_params = []\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'reg_alpha': [0.0, 0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "for train_index, test_index in kf.split(data, target):\n",
    "    \n",
    "    # Dividir os dados em conjuntos de treino e teste\n",
    "    X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Aplicação do oversampling no conjunto de treino\n",
    "    smote = SMOTE(sampling_strategy=0.55, k_neighbors=7, random_state=22)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Treinamento do modelo\n",
    "    model = XGBClassifier()\n",
    "    f1_scorer = make_scorer(f1_score, pos_label=1)\n",
    "    grid_search = GridSearchCV(model, param_grid, scoring=f1_scorer, cv=3)\n",
    "    grid_search.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params.append(grid_search.best_params_)\n",
    "    \n",
    "    y_scores = best_model.predict_proba(X_test)[:, 1]\n",
    "    m = findBestTresh(best_model,X_test)\n",
    "    best_thresholds.append(m)\n",
    "    y_pred_adjusted = (y_scores >= m).astype(int)\n",
    "    \n",
    "    final_predictions.extend(y_pred_adjusted)\n",
    "    final_targets.extend(y_test)\n",
    "    print()\n",
    "\n",
    "average_threshold = np.mean(best_thresholds)\n",
    "best_params_avg = {k: np.mean([param[k] for param in best_params]) for k in best_params[0]}\n",
    "\n",
    "print(best_params_avg)\n",
    "\n",
    "print(classification_report(final_targets, final_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X = df_clean_faixa_idade.drop(columns=['y'])\n",
    "y = df_clean_faixa_idade['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=22)\n",
    "\n",
    "smote = SMOTE(sampling_strategy=0.55, k_neighbors=3, random_state=22)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teste\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92      5588\n",
      "           1       0.46      0.71      0.56       782\n",
      "\n",
      "    accuracy                           0.86      6370\n",
      "   macro avg       0.71      0.80      0.74      6370\n",
      "weighted avg       0.90      0.86      0.88      6370\n",
      "\n",
      "Predictions saved to predictions.csv\n"
     ]
    }
   ],
   "source": [
    "#treinar modelo\n",
    "best_params_avg = {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 200, 'reg_alpha': 0.02}\n",
    "\n",
    "final_model = XGBClassifier(**best_params_avg)\n",
    "final_model.fit(X_train_res, y_train_res)\n",
    "#threshhold\n",
    "\n",
    "y_scores = final_model.predict_proba(X_test)[:, 1]\n",
    "y_pred_adjusted = (y_scores >= average_threshold).astype(int)\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "print(\"teste\")\n",
    "print(classification_report(y_test, y_pred_adjusted))\n",
    "predictions_threshhold(final_model,average_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validação cruzada com GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold: 0.28\n",
      "Best Precision: 0.48\n",
      "Best Recall: 0.81\n",
      "Best F1 Score: 0.60\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.93      3128\n",
      "           1       0.48      0.81      0.60       411\n",
      "\n",
      "    accuracy                           0.87      3539\n",
      "   macro avg       0.72      0.85      0.76      3539\n",
      "weighted avg       0.91      0.87      0.89      3539\n",
      "\n",
      "Optimal Threshold: 0.32\n",
      "Best Precision: 0.45\n",
      "Best Recall: 0.73\n",
      "Best F1 Score: 0.56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.92      3128\n",
      "           1       0.45      0.73      0.56       411\n",
      "\n",
      "    accuracy                           0.87      3539\n",
      "   macro avg       0.71      0.81      0.74      3539\n",
      "weighted avg       0.90      0.87      0.88      3539\n",
      "\n",
      "Optimal Threshold: 0.36\n",
      "Best Precision: 0.48\n",
      "Best Recall: 0.71\n",
      "Best F1 Score: 0.57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93      3128\n",
      "           1       0.48      0.71      0.57       411\n",
      "\n",
      "    accuracy                           0.88      3539\n",
      "   macro avg       0.72      0.80      0.75      3539\n",
      "weighted avg       0.90      0.88      0.89      3539\n",
      "\n",
      "Optimal Threshold: 0.34\n",
      "Best Precision: 0.47\n",
      "Best Recall: 0.75\n",
      "Best F1 Score: 0.58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.92      3128\n",
      "           1       0.47      0.75      0.58       411\n",
      "\n",
      "    accuracy                           0.87      3539\n",
      "   macro avg       0.72      0.82      0.75      3539\n",
      "weighted avg       0.91      0.87      0.88      3539\n",
      "\n",
      "Optimal Threshold: 0.27\n",
      "Best Precision: 0.45\n",
      "Best Recall: 0.81\n",
      "Best F1 Score: 0.58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92      3128\n",
      "           1       0.45      0.81      0.58       410\n",
      "\n",
      "    accuracy                           0.86      3538\n",
      "   macro avg       0.71      0.84      0.75      3538\n",
      "weighted avg       0.91      0.86      0.88      3538\n",
      "\n",
      "Optimal Threshold: 0.37\n",
      "Best Precision: 0.48\n",
      "Best Recall: 0.71\n",
      "Best F1 Score: 0.57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93      3128\n",
      "           1       0.48      0.71      0.57       410\n",
      "\n",
      "    accuracy                           0.88      3538\n",
      "   macro avg       0.72      0.80      0.75      3538\n",
      "weighted avg       0.90      0.88      0.89      3538\n",
      "\n",
      "Optimal Threshold: 0.36\n",
      "Best Precision: 0.50\n",
      "Best Recall: 0.71\n",
      "Best F1 Score: 0.59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93      3128\n",
      "           1       0.50      0.71      0.59       410\n",
      "\n",
      "    accuracy                           0.88      3538\n",
      "   macro avg       0.73      0.81      0.76      3538\n",
      "weighted avg       0.91      0.88      0.89      3538\n",
      "\n",
      "Optimal Threshold: 0.41\n",
      "Best Precision: 0.56\n",
      "Best Recall: 0.68\n",
      "Best F1 Score: 0.61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94      3128\n",
      "           1       0.56      0.68      0.61       410\n",
      "\n",
      "    accuracy                           0.90      3538\n",
      "   macro avg       0.76      0.81      0.78      3538\n",
      "weighted avg       0.91      0.90      0.91      3538\n",
      "\n",
      "Optimal Threshold: 0.36\n",
      "Best Precision: 0.49\n",
      "Best Recall: 0.71\n",
      "Best F1 Score: 0.58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93      3128\n",
      "           1       0.49      0.71      0.58       410\n",
      "\n",
      "    accuracy                           0.88      3538\n",
      "   macro avg       0.73      0.81      0.76      3538\n",
      "weighted avg       0.91      0.88      0.89      3538\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93      3128\n",
      "           1       0.49      0.71      0.58       410\n",
      "\n",
      "    accuracy                           0.88      3538\n",
      "   macro avg       0.73      0.81      0.76      3538\n",
      "weighted avg       0.91      0.88      0.89      3538\n",
      "\n",
      "Predictions saved to predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Supondo que df_clean_faixa_idade já esteja carregado\n",
    "\n",
    "data, target = df_clean_faixa_idade.drop(columns=['y']), df_clean_faixa_idade['y']\n",
    "kf = StratifiedKFold(n_splits=9, shuffle=True, random_state=22)\n",
    "\n",
    "# Inicializar variáveis para armazenar os resultados\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "\n",
    "# Função findBestTresh (supondo que ela já existe)\n",
    "\n",
    "for train_index, test_index in kf.split(data, target):\n",
    "    # Dividir os dados em conjuntos de treino e teste\n",
    "    X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "    y_train, y_test = target.iloc[train_index], target.iloc[test_index]\n",
    "    \n",
    "    # Aplicação do oversampling no conjunto de treino\n",
    "    smote = SMOTE(sampling_strategy=0.55, k_neighbors=7, random_state=22)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Treinamento do modelo\n",
    "    best_model.fit(X_resampled, y_resampled)\n",
    "    m = findBestTresh(best_model, X_test)\n",
    "    y_scores = best_model.predict_proba(X_test)[:, 1]\n",
    "    y_pred_adjusted = (y_scores >= m).astype(int)\n",
    "    \n",
    "    # Avaliar o modelo\n",
    "    accuracies.append(accuracy_score(y_test, y_pred_adjusted))\n",
    "    precisions.append(precision_score(y_test, y_pred_adjusted))\n",
    "    recalls.append(recall_score(y_test, y_pred_adjusted))\n",
    "    f1s.append(f1_score(y_test, y_pred_adjusted))\n",
    "    print(classification_report(y_test, y_pred_adjusted))\n",
    "# Mostrar os resultados agregados\n",
    "# print(f'Accuracy: {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}')\n",
    "# print(f'Precision: {np.mean(precisions):.4f} ± {np.std(precisions):.4f}')\n",
    "# print(f'Recall: {np.mean(recalls):.4f} ± {np.std(recalls):.4f}')\n",
    "# print(f'F1 Score: {np.mean(f1s):.4f} ± {np.std(f1s):.4f}')\n",
    "\n",
    "# Imprimir o relatório de classificação final\n",
    "print(classification_report(y_test, y_pred_adjusted))\n",
    "predictions_threshhold(best_model,m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excluir linhas do dataset para ver se altera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de alteração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Função para avaliar a remoção de colunas\n",
    "def teste_excluir_colunas(df, target_column,model,X_train_res,y_train_res,X_test):\n",
    "    results = {}\n",
    "    \n",
    "    # Separar as features e o target\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    base_score = f1_score(y_test, y_pred)\n",
    "    \n",
    "    results['base_model'] = base_score\n",
    "    \n",
    "    # Avaliar a remoção de cada coluna\n",
    "    for column in X.columns:\n",
    "        X_temp = X.drop(columns=[column])\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_temp, y, test_size=0.2, random_state=22)\n",
    "        X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "        \n",
    "        model.fit(X_train_res, y_train_res)\n",
    "        y_pred = model.predict(X_test)\n",
    "        score = f1_score(y_test, y_pred)\n",
    "        \n",
    "        results[column] = score\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_clean_sem_coluna = df_clean.copy()\n",
    "X = df_clean_sem_coluna.drop(columns=['y'])\n",
    "y = df_clean_sem_coluna['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(sampling_strategy=0.55, k_neighbors=3, random_state=22)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jvmil\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:158: UserWarning: [09:02:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros: {'colsample_bytree': 1.0, 'gamma': 0, 'learning_rate': 0.02, 'max_depth': 10, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.0, 'subsample': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jvmil\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:158: UserWarning: [09:02:50] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=0, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.02, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,\n",
       "              max_leaves=None, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
       "              feature_types=None, gamma=0, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.02, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,\n",
       "              max_leaves=None, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric='logloss',\n",
       "              feature_types=None, gamma=0, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.02, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=10,\n",
       "              max_leaves=None, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=100,\n",
       "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Supondo que X_train_res e y_train_res já estejam definidos\n",
    "\n",
    "# Definir o classificador e o grid de parâmetros\n",
    "xgb = XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'max_depth': [3, 5, 7, 10],\n",
    "#     'learning_rate': [0.01, 0.02, 0.05, 0.1],\n",
    "#     'reg_alpha': [0.0, 0.1, 0.5, 1.0],\n",
    "#     'subsample': [0.6, 0.8, 1.0],\n",
    "#     'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "#     'min_child_weight': [1, 3, 5],\n",
    "#     'gamma': [0, 0.1, 0.3, 0.5]\n",
    "# }\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [10],\n",
    "    'learning_rate': [0.02],\n",
    "    'reg_alpha': [0.0],\n",
    "    'subsample': [1.0],\n",
    "    'colsample_bytree': [1.0],\n",
    "    'min_child_weight': [1],\n",
    "    'gamma': [0]\n",
    "}\n",
    "\n",
    "# Usar GridSearchCV para encontrar os melhores hiperparâmetros\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=5, scoring='f1', verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Melhor combinação de hiperparâmetros\n",
    "print(\"Melhores hiperparâmetros:\", grid_search.best_params_)\n",
    "\n",
    "# Treinar o modelo com os melhores hiperparâmetros\n",
    "best_params = grid_search.best_params_\n",
    "best_model = XGBClassifier(**best_params, use_label_encoder=False, eval_metric='logloss')\n",
    "best_model.fit(X_train_res, y_train_res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função de threshhold + gerar resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def resultado_threshold(modelo_treinado):\n",
    "    #threshhold\n",
    "    m = findBestTresh(modelo_treinado,X_test)\n",
    "    y_scores = modelo_treinado.predict_proba(X_test)[:, 1]\n",
    "    y_pred_adjusted = (y_scores >= m).astype(int)\n",
    "    y_pred = modelo_treinado.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    print('Classification Report:\\n', report)\n",
    "    print(classification_report(y_test, y_pred_adjusted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['age', 'job', 'marital', 'education', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous'] ['age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous']\ntraining data did not have the following fields: default",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m resultado \u001b[38;5;241m=\u001b[39m \u001b[43mteste_excluir_colunas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_clean_sem_coluna\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbest_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_train_res\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train_res\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(resultado)\n",
      "Cell \u001b[1;32mIn[50], line 15\u001b[0m, in \u001b[0;36mteste_excluir_colunas\u001b[1;34m(df, target_column, model, X_train_res, y_train_res, X_test)\u001b[0m\n\u001b[0;32m     12\u001b[0m X \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[target_column])\n\u001b[0;32m     13\u001b[0m y \u001b[38;5;241m=\u001b[39m df[target_column]\n\u001b[1;32m---> 15\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m base_score \u001b[38;5;241m=\u001b[39m f1_score(y_test, y_pred)\n\u001b[0;32m     18\u001b[0m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase_model\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m base_score\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\sklearn.py:1565\u001b[0m, in \u001b[0;36mXGBClassifier.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     X: ArrayLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1562\u001b[0m     iteration_range: Optional[IterationRange] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1563\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[0;32m   1564\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity):\n\u001b[1;32m-> 1565\u001b[0m         class_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1566\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1567\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1568\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1569\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1570\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1571\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1572\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output_margin:\n\u001b[0;32m   1573\u001b[0m             \u001b[38;5;66;03m# If output_margin is active, simply return the scores\u001b[39;00m\n\u001b[0;32m   1574\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m class_probs\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\sklearn.py:1186\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[0;32m   1185\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1186\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1187\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1188\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1189\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmargin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1190\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1191\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1192\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1194\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_alike(predts):\n\u001b[0;32m   1195\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:2510\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[0;32m   2508\u001b[0m     data, fns, _ \u001b[38;5;241m=\u001b[39m _transform_pandas_df(data, enable_categorical)\n\u001b[0;32m   2509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m validate_features:\n\u001b[1;32m-> 2510\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_list(data) \u001b[38;5;129;01mor\u001b[39;00m _is_tuple(data):\n\u001b[0;32m   2512\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:3075\u001b[0m, in \u001b[0;36mBooster._validate_features\u001b[1;34m(self, feature_names)\u001b[0m\n\u001b[0;32m   3069\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m my_missing:\n\u001b[0;32m   3070\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   3071\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtraining data did not have the following fields: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3072\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m my_missing)\n\u001b[0;32m   3073\u001b[0m     )\n\u001b[1;32m-> 3075\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names, feature_names))\n",
      "\u001b[1;31mValueError\u001b[0m: feature_names mismatch: ['age', 'job', 'marital', 'education', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous'] ['age', 'job', 'marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous']\ntraining data did not have the following fields: default"
     ]
    }
   ],
   "source": [
    "resultado = teste_excluir_colunas(df_clean_sem_coluna,'y',best_model,X_train_res,y_train_res,X_test)\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gepeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jvmil\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:158: UserWarning: [09:51:20] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\jvmil\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:158: UserWarning: [09:51:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coluna não usada:  age\n",
      "Accuracy: 0.89\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93      5588\n",
      "           1       0.53      0.66      0.59       782\n",
      "\n",
      "    accuracy                           0.89      6370\n",
      "   macro avg       0.74      0.79      0.76      6370\n",
      "weighted avg       0.90      0.89      0.89      6370\n",
      "\n",
      "Resultado sem thredhhold alterado\n",
      "Accuracy: 0.89\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      5588\n",
      "           1       0.57      0.54      0.56       782\n",
      "\n",
      "    accuracy                           0.89      6370\n",
      "   macro avg       0.75      0.74      0.75      6370\n",
      "weighted avg       0.89      0.89      0.89      6370\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jvmil\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:158: UserWarning: [09:51:21] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coluna não usada:  job\n",
      "Accuracy: 0.89\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93      5588\n",
      "           1       0.53      0.67      0.59       782\n",
      "\n",
      "    accuracy                           0.89      6370\n",
      "   macro avg       0.74      0.79      0.76      6370\n",
      "weighted avg       0.90      0.89      0.89      6370\n",
      "\n",
      "Resultado sem thredhhold alterado\n",
      "Accuracy: 0.89\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      5588\n",
      "           1       0.58      0.54      0.56       782\n",
      "\n",
      "    accuracy                           0.89      6370\n",
      "   macro avg       0.76      0.74      0.75      6370\n",
      "weighted avg       0.89      0.89      0.89      6370\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jvmil\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:158: UserWarning: [09:51:22] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coluna não usada:  marital\n",
      "Accuracy: 0.88\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      5588\n",
      "           1       0.52      0.66      0.58       782\n",
      "\n",
      "    accuracy                           0.88      6370\n",
      "   macro avg       0.74      0.79      0.76      6370\n",
      "weighted avg       0.90      0.88      0.89      6370\n",
      "\n",
      "Resultado sem thredhhold alterado\n",
      "Accuracy: 0.89\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      5588\n",
      "           1       0.57      0.56      0.56       782\n",
      "\n",
      "    accuracy                           0.89      6370\n",
      "   macro avg       0.75      0.75      0.75      6370\n",
      "weighted avg       0.89      0.89      0.89      6370\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jvmil\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:158: UserWarning: [09:51:22] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coluna não usada:  education\n",
      "Accuracy: 0.89\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93      5588\n",
      "           1       0.53      0.68      0.59       782\n",
      "\n",
      "    accuracy                           0.89      6370\n",
      "   macro avg       0.74      0.79      0.76      6370\n",
      "weighted avg       0.90      0.89      0.89      6370\n",
      "\n",
      "Resultado sem thredhhold alterado\n",
      "Accuracy: 0.89\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      5588\n",
      "           1       0.56      0.56      0.56       782\n",
      "\n",
      "    accuracy                           0.89      6370\n",
      "   macro avg       0.75      0.75      0.75      6370\n",
      "weighted avg       0.89      0.89      0.89      6370\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jvmil\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:158: UserWarning: [09:51:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coluna não usada:  default\n",
      "Accuracy: 0.89\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94      5588\n",
      "           1       0.54      0.66      0.59       782\n",
      "\n",
      "    accuracy                           0.89      6370\n",
      "   macro avg       0.74      0.79      0.76      6370\n",
      "weighted avg       0.90      0.89      0.89      6370\n",
      "\n",
      "Resultado sem thredhhold alterado\n",
      "Accuracy: 0.89\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      5588\n",
      "           1       0.56      0.53      0.55       782\n",
      "\n",
      "    accuracy                           0.89      6370\n",
      "   macro avg       0.75      0.74      0.74      6370\n",
      "weighted avg       0.89      0.89      0.89      6370\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jvmil\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:158: UserWarning: [09:51:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coluna não usada:  balance\n",
      "Accuracy: 0.89\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93      5588\n",
      "           1       0.53      0.65      0.58       782\n",
      "\n",
      "    accuracy                           0.89      6370\n",
      "   macro avg       0.74      0.78      0.76      6370\n",
      "weighted avg       0.90      0.89      0.89      6370\n",
      "\n",
      "Resultado sem thredhhold alterado\n",
      "Accuracy: 0.89\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      5588\n",
      "           1       0.57      0.55      0.56       782\n",
      "\n",
      "    accuracy                           0.89      6370\n",
      "   macro avg       0.75      0.75      0.75      6370\n",
      "weighted avg       0.89      0.89      0.89      6370\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jvmil\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:158: UserWarning: [09:51:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coluna não usada:  housing\n",
      "Accuracy: 0.88\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93      5588\n",
      "           1       0.52      0.63      0.57       782\n",
      "\n",
      "    accuracy                           0.88      6370\n",
      "   macro avg       0.73      0.77      0.75      6370\n",
      "weighted avg       0.89      0.88      0.89      6370\n",
      "\n",
      "Resultado sem thredhhold alterado\n",
      "Accuracy: 0.89\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      5588\n",
      "           1       0.58      0.47      0.52       782\n",
      "\n",
      "    accuracy                           0.89      6370\n",
      "   macro avg       0.75      0.71      0.73      6370\n",
      "weighted avg       0.88      0.89      0.89      6370\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jvmil\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:158: UserWarning: [09:51:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coluna não usada:  loan\n",
      "Accuracy: 0.88\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93      5588\n",
      "           1       0.52      0.66      0.59       782\n",
      "\n",
      "    accuracy                           0.88      6370\n",
      "   macro avg       0.74      0.79      0.76      6370\n",
      "weighted avg       0.90      0.88      0.89      6370\n",
      "\n",
      "Resultado sem thredhhold alterado\n",
      "Accuracy: 0.89\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      5588\n",
      "           1       0.56      0.54      0.55       782\n",
      "\n",
      "    accuracy                           0.89      6370\n",
      "   macro avg       0.75      0.74      0.74      6370\n",
      "weighted avg       0.89      0.89      0.89      6370\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jvmil\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:158: UserWarning: [09:51:25] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coluna não usada:  contact\n",
      "Accuracy: 0.88\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93      5588\n",
      "           1       0.52      0.62      0.57       782\n",
      "\n",
      "    accuracy                           0.88      6370\n",
      "   macro avg       0.73      0.77      0.75      6370\n",
      "weighted avg       0.89      0.88      0.89      6370\n",
      "\n",
      "Resultado sem thredhhold alterado\n",
      "Accuracy: 0.89\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      5588\n",
      "           1       0.57      0.51      0.54       782\n",
      "\n",
      "    accuracy                           0.89      6370\n",
      "   macro avg       0.75      0.73      0.74      6370\n",
      "weighted avg       0.89      0.89      0.89      6370\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jvmil\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:158: UserWarning: [09:51:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coluna não usada:  day\n",
      "Accuracy: 0.88\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93      5588\n",
      "           1       0.52      0.64      0.57       782\n",
      "\n",
      "    accuracy                           0.88      6370\n",
      "   macro avg       0.73      0.78      0.75      6370\n",
      "weighted avg       0.90      0.88      0.89      6370\n",
      "\n",
      "Resultado sem thredhhold alterado\n",
      "Accuracy: 0.89\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94      5588\n",
      "           1       0.56      0.53      0.54       782\n",
      "\n",
      "    accuracy                           0.89      6370\n",
      "   macro avg       0.75      0.74      0.74      6370\n",
      "weighted avg       0.89      0.89      0.89      6370\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jvmil\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:158: UserWarning: [09:51:26] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coluna não usada:  month\n",
      "Accuracy: 0.88\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93      5588\n",
      "           1       0.50      0.60      0.54       782\n",
      "\n",
      "    accuracy                           0.88      6370\n",
      "   macro avg       0.72      0.76      0.74      6370\n",
      "weighted avg       0.89      0.88      0.88      6370\n",
      "\n",
      "Resultado sem thredhhold alterado\n",
      "Accuracy: 0.88\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93      5588\n",
      "           1       0.53      0.46      0.49       782\n",
      "\n",
      "    accuracy                           0.88      6370\n",
      "   macro avg       0.73      0.70      0.71      6370\n",
      "weighted avg       0.88      0.88      0.88      6370\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jvmil\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:158: UserWarning: [09:51:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coluna não usada:  duration\n",
      "Accuracy: 0.87\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93      5588\n",
      "           1       0.46      0.37      0.41       782\n",
      "\n",
      "    accuracy                           0.87      6370\n",
      "   macro avg       0.68      0.65      0.67      6370\n",
      "weighted avg       0.86      0.87      0.86      6370\n",
      "\n",
      "Resultado sem thredhhold alterado\n",
      "Accuracy: 0.88\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93      5588\n",
      "           1       0.49      0.29      0.36       782\n",
      "\n",
      "    accuracy                           0.88      6370\n",
      "   macro avg       0.70      0.62      0.65      6370\n",
      "weighted avg       0.86      0.88      0.86      6370\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jvmil\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:158: UserWarning: [09:51:27] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coluna não usada:  campaign\n",
      "Accuracy: 0.89\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93      5588\n",
      "           1       0.53      0.67      0.59       782\n",
      "\n",
      "    accuracy                           0.89      6370\n",
      "   macro avg       0.74      0.79      0.76      6370\n",
      "weighted avg       0.90      0.89      0.89      6370\n",
      "\n",
      "Resultado sem thredhhold alterado\n",
      "Accuracy: 0.89\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      5588\n",
      "           1       0.57      0.55      0.56       782\n",
      "\n",
      "    accuracy                           0.89      6370\n",
      "   macro avg       0.76      0.75      0.75      6370\n",
      "weighted avg       0.89      0.89      0.89      6370\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jvmil\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:158: UserWarning: [09:51:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coluna não usada:  pdays\n",
      "Accuracy: 0.89\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93      5588\n",
      "           1       0.53      0.67      0.59       782\n",
      "\n",
      "    accuracy                           0.89      6370\n",
      "   macro avg       0.74      0.79      0.76      6370\n",
      "weighted avg       0.90      0.89      0.89      6370\n",
      "\n",
      "Resultado sem thredhhold alterado\n",
      "Accuracy: 0.89\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      5588\n",
      "           1       0.57      0.57      0.57       782\n",
      "\n",
      "    accuracy                           0.89      6370\n",
      "   macro avg       0.76      0.76      0.76      6370\n",
      "weighted avg       0.89      0.89      0.89      6370\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jvmil\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\core.py:158: UserWarning: [09:51:28] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-06abd128ca6c1688d-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coluna não usada:  previous\n",
      "Accuracy: 0.89\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93      5588\n",
      "           1       0.53      0.66      0.59       782\n",
      "\n",
      "    accuracy                           0.89      6370\n",
      "   macro avg       0.74      0.79      0.76      6370\n",
      "weighted avg       0.90      0.89      0.89      6370\n",
      "\n",
      "Resultado sem thredhhold alterado\n",
      "Accuracy: 0.89\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      5588\n",
      "           1       0.57      0.54      0.55       782\n",
      "\n",
      "    accuracy                           0.89      6370\n",
      "   macro avg       0.75      0.74      0.75      6370\n",
      "weighted avg       0.89      0.89      0.89      6370\n",
      "\n",
      "{'base_model': 0.5899942495687176, 'age': 0.5876347135564379, 'job': 0.5880361173814899, 'marital': 0.5836139169472503, 'education': 0.5909345271404589, 'default': 0.5912743972445464, 'balance': 0.5812356979405034, 'housing': 0.5682997118155619, 'loan': 0.5856416054267948, 'contact': 0.5652930934416716, 'day': 0.5730593607305936, 'month': 0.543768115942029, 'duration': 0.4056737588652482, 'campaign': 0.5930956423316356, 'pdays': 0.5943502824858757, 'previous': 0.5876993166287016}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, precision_recall_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Função para encontrar o melhor limiar de decisão baseado na métrica F1\n",
    "\n",
    "# Função para avaliar a remoção de colunas\n",
    "def teste_excluir_colunas(df, target_column, model):\n",
    "    results = {}\n",
    "    \n",
    "    # Separar as features e o target\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    \n",
    "    # Treinar e avaliar o modelo com todas as colunas\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=22)\n",
    "    smote = SMOTE(sampling_strategy=0.55, k_neighbors=3, random_state=22)\n",
    "    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    model.fit(X_train_res, y_train_res)\n",
    "    m = findBestTresh(model, X_test)\n",
    "    y_scores = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred_adjusted = (y_scores >= m).astype(int)\n",
    "    base_score = f1_score(y_test, y_pred_adjusted)\n",
    "    \n",
    "    results['base_model'] = base_score\n",
    "    \n",
    "    # Avaliar a remoção de cada coluna\n",
    "    for column in X.columns:\n",
    "        X_temp = X.drop(columns=[column])\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_temp, y, test_size=0.2, random_state=22)\n",
    "        X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "        \n",
    "        model.fit(X_train_res, y_train_res)\n",
    "        y_scores = model.predict_proba(X_test)[:, 1]\n",
    "        y_pred_adjusted = (y_scores >= m).astype(int)\n",
    "        score = f1_score(y_test, y_pred_adjusted)\n",
    "        print(\"Coluna não usada: \",column)\n",
    "        resultado_threshold(best_model, X_test, y_test,m)\n",
    "        print(\"Resultado sem thredhhold alterado\")\n",
    "        resultado(best_model, X_test, y_test,m)\n",
    "        \n",
    "        results[column] = score\n",
    "    \n",
    "    return results\n",
    "# Preparar os dados\n",
    "df_clean_sem_coluna = df_clean.copy()\n",
    "X = df_clean_sem_coluna.drop(columns=['y'])\n",
    "y = df_clean_sem_coluna['y']\n",
    "\n",
    "# Dividir os dados\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=22)\n",
    "\n",
    "# Aplicar oversampling\n",
    "smote = SMOTE(sampling_strategy=0.55, k_neighbors=3, random_state=22)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Função para imprimir o relatório de classificação e acurácia\n",
    "def resultado_threshold(modelo_treinado, X_test, y_test,m):\n",
    "    y_scores = modelo_treinado.predict_proba(X_test)[:, 1]\n",
    "    y_pred_adjusted = (y_scores >= m).astype(int)\n",
    "    accuracy = accuracy_score(y_test, y_pred_adjusted)\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    report = classification_report(y_test, y_pred_adjusted)\n",
    "    print('Classification Report:\\n', report)\n",
    "\n",
    "def resultado(modelo_treinado, X_test, y_test,m):\n",
    "    y_scores = modelo_treinado.predict_proba(X_test)[:, 1]\n",
    "    y_pred_adjusted = (y_scores >= 0.5).astype(int)\n",
    "    accuracy = accuracy_score(y_test, y_pred_adjusted)\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    report = classification_report(y_test, y_pred_adjusted)\n",
    "    print('Classification Report:\\n', report)\n",
    "\n",
    "# Avaliar a remoção de colunas\n",
    "resultado = teste_excluir_colunas(df_clean_sem_coluna, 'y', best_model)\n",
    "print(resultado)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
